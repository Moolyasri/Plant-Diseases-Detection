# Plant-Diseases-Detection
from google.colab import drive
# Mount Google Drive
drive.mount('/content/drive')

# Import necessary libraries
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

# Set up ImageDataGenerators for training and validation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_datagen = ImageDataGenerator(rescale=1./255)

# Load images from the directory
train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/DiseasesDataset/Disease/train',  # Correct path to training data
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

validation_generator = val_datagen.flow_from_directory(
    '/content/drive/MyDrive/DiseasesDataset/Disease/valid',  # Correct path to validation data
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# Check the number of classes
num_classes = train_generator.num_classes
print(f"Number of classes in training data: {num_classes}")
print(f"Class labels: {train_generator.class_indices}")

# Load EfficientNet model with pre-trained weights
base_model = tf.keras.applications.EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False

# Build the model
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(num_classes, activation='softmax')  # Ensure the number of classes is correct
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(
    train_generator,
    epochs=3,  # Adjust based on your data
    validation_data=validation_generator
)

# Unfreeze some layers for fine-tuning
base_model.trainable = True
model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])

# Fine-tune the model
fine_tune_history = model.fit(
    train_generator,
    epochs=3,  # Fine-tuning epochs
    validation_data=validation_generator
)

# Plot Accuracy and Loss over Epochs
plt.figure(figsize=(12, 4))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.plot(fine_tune_history.history['accuracy'], label='Fine-Tuned Training Accuracy')
plt.plot(fine_tune_history.history['val_accuracy'], label='Fine-Tuned Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.plot(fine_tune_history.history['loss'], label='Fine-Tuned Training Loss')
plt.plot(fine_tune_history.history['val_loss'], label='Fine-Tuned Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

# Evaluate the model and create a Confusion Matrix
# Re-load validation data (with shuffle=False to maintain order)
val_generator = val_datagen.flow_from_directory(
    '/content/drive/MyDrive/DiseasesDataset/Disease/valid',  # Correct path to validation data
    target_size=(224, 224),
    batch_size=1,
    class_mode='categorical',
    shuffle=False
)

# Get predictions
Y_pred = model.predict(val_generator)
y_pred = np.argmax(Y_pred, axis=1)

# Confusion Matrix
cm = confusion_matrix(val_generator.classes, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=val_generator.class_indices.keys(), yticklabels=val_generator.class_indices.keys())
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

# Classification Report
print(classification_report(val_generator.classes, y_pred, target_names=val_generator.class_indices.keys()))
model.save('/content/drive/MyDrive/DiseasesDataset/saved_model.h5')


import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# Step 1: Load the Saved Model
model_path = '/content/drive/MyDrive/DiseasesDataset/saved_model.h5'  # Replace with your model's path
model = load_model(model_path)

# Step 2: Load and Preprocess the Image
def preprocess_image(image_path, target_size):
    image = load_img(image_path, target_size=target_size)  # Resize image to model input size
    image = img_to_array(image)  # Convert to NumPy array
    image = np.expand_dims(image, axis=0)  # Add batch dimension
    image = image / 255.0  # Normalize to [0, 1]
    return image

image_path = '/content/drive/MyDrive/DiseasesDataset/y.JPG'  # Replace with your image path
input_image = preprocess_image(image_path, target_size=(224, 224))  # Update size as per your model

# Step 3: Make a Prediction
predictions = model.predict(input_image)
predicted_class = np.argmax(predictions, axis=-1)  # Get the class index

# Map the predicted class index to disease names
disease_classes = ['Apple___Apple_scab', 'Apple___Black_rot','Apple___Cedar_apple_rust','Apple___healthy',' Blueberry___healthy','Cherry_(including_sour)___Powdery_mildew','Cherry_(including_sour)___healthy']  # Update with your classes
predicted_disease = disease_classes[predicted_class[0]]

# Step 4: Output the Prediction
print(f"The leaf is diagnosed as: {predicted_disease}")


def plot_metrics(train_losses, val_losses, train_accuracies, val_accuracies):
    # Create figure and axes
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

    # Plot losses
    ax1.plot(train_losses, label='Train Loss', color='blue', linewidth=2)
    ax1.plot(val_losses, label='Validation Loss', color='red', linewidth=2)
    ax1.set_title('Loss vs. Epochs', fontsize=12, pad=10)
    ax1.set_xlabel('Epochs', fontsize=10)
    ax1.set_ylabel('Loss', fontsize=10)
    ax1.legend(fontsize=10)
    ax1.grid(True, linestyle='--', alpha=0.7)

    # Plot accuracies
    ax2.plot(train_accuracies, label='Train Accuracy', color='blue', linewidth=2)
    ax2.plot(val_accuracies, label='Validation Accuracy', color='red', linewidth=2)
    ax2.set_title('Accuracy vs. Epochs', fontsize=12, pad=10)
    ax2.set_xlabel('Epochs', fontsize=10)
    ax2.set_ylabel('Accuracy', fontsize=10)
    ax2.legend(fontsize=10)
    ax2.grid(True, linestyle='--', alpha=0.7)

    # Adjust layout
    plt.tight_layout()


    # Display the plot
    plt.show()
    model.save('/content/drive/MyDrive/DiseasesDataset/saved_model.h5')


    from google.colab import files

# Download the model
files.download('/content/drive/MyDrive/DiseasesDataset/Disease/saved_model.h5')  # This will prompt the file download
